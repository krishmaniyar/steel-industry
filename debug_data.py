#!/usr/bin/env python3
"""
Debug script to diagnose issues with the transformed data
"""

import pandas as pd
import numpy as np
import joblib

def diagnose_data():
    print("=" * 60)
    print("DATA TRANSFORMATION DIAGNOSIS")
    print("=" * 60)
    
    try:
        # Load the data
        print("\n1. Loading data...")
        df = pd.read_csv('transformed_data.csv')
        print(f"‚úì Data loaded: {df.shape}")
        
        # Load feature names
        try:
            feature_names = joblib.load('feature_names.pkl')
            print(f"‚úì Feature names loaded: {len(feature_names)} features")
        except:
            print("‚ö†Ô∏è Could not load feature_names.pkl, using all columns except 'target'")
            feature_names = [col for col in df.columns if col != 'target']
        
        # Check target column
        print("\n2. Checking target variable...")
        if 'target' in df.columns:
            target = df['target']
            print(f"‚úì Target column found: {target.name}")
            print(f"  Data type: {target.dtype}")
            print(f"  Unique values: {sorted(target.unique())}")
            print(f"  Value counts: {target.value_counts().to_dict()}")
        else:
            print("‚ùå No 'target' column found!")
            print(f"Available columns: {list(df.columns)}")
        
        # Check features
        print("\n3. Checking features...")
        X = df[feature_names]
        
        print(f"Feature matrix shape: {X.shape}")
        print(f"Feature data types:")
        dtype_counts = X.dtypes.value_counts()
        for dtype, count in dtype_counts.items():
            print(f"  {dtype}: {count} columns")
        
        # Check for string/object columns
        string_cols = X.select_dtypes(include=['object']).columns.tolist()
        if string_cols:
            print(f"\n‚ùå ISSUE FOUND: String columns in features!")
            print(f"String columns: {string_cols}")
            
            # Show sample values from string columns
            for col in string_cols[:3]:  # Show first 3 string columns
                print(f"\n{col} sample values:")
                print(X[col].value_counts().head())
        else:
            print("\n‚úì No string columns found in features")
        
        # Check for missing values
        print("\n4. Checking for missing values...")
        missing_features = X.isnull().sum()
        if missing_features.sum() > 0:
            print("‚ö†Ô∏è Missing values found:")
            print(missing_features[missing_features > 0])
        else:
            print("‚úì No missing values in features")
        
        # Check for infinite values
        print("\n5. Checking for infinite values...")
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            inf_count = np.isinf(X[numeric_cols]).sum().sum()
            if inf_count > 0:
                print(f"‚ö†Ô∏è Found {inf_count} infinite values")
                inf_cols = X[numeric_cols].columns[np.isinf(X[numeric_cols]).any()]
                print(f"Columns with infinite values: {inf_cols.tolist()}")
            else:
                print("‚úì No infinite values found")
        
        # Summary
        print("\n" + "=" * 60)
        print("DIAGNOSIS SUMMARY")
        print("=" * 60)
        
        issues = []
        if 'target' not in df.columns:
            issues.append("Missing 'target' column")
        
        if string_cols:
            issues.append(f"String columns in features: {string_cols}")
        
        if missing_features.sum() > 0:
            issues.append("Missing values in features")
        
        if len(numeric_cols) > 0 and np.isinf(X[numeric_cols]).sum().sum() > 0:
            issues.append("Infinite values in features")
        
        if issues:
            print("‚ùå ISSUES FOUND:")
            for i, issue in enumerate(issues, 1):
                print(f"  {i}. {issue}")
            
            print("\nüîß RECOMMENDED FIXES:")
            if string_cols:
                print("  - Re-run the data transformation notebook (03_data_transformation.ipynb)")
                print("  - Check categorical encoding section")
            
        else:
            print("‚úÖ No issues found! Data should be ready for modeling.")
        
        return issues
        
    except FileNotFoundError as e:
        print(f"‚ùå File not found: {e}")
        print("Make sure you've run the previous notebooks in order:")
        print("  1. 01_data_ingestion.ipynb")
        print("  2. 02_data_validation.ipynb") 
        print("  3. 03_data_transformation.ipynb")
        return ["Missing data files"]
    
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return [f"Error: {e}"]

if __name__ == "__main__":
    issues = diagnose_data()
    
    if issues:
        print(f"\n‚ö†Ô∏è Found {len(issues)} issue(s). Please fix before training models.")
        exit(1)
    else:
        print("\nüéâ Data looks good! You can proceed with model training.")
        exit(0)
